from __future__ import annotations

import json
from pathlib import Path
from typing import Tuple

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve

from spam_classification.train import train as train_fn
from spam_classification.infer import infer_single, load_pipeline
from spam_classification.data import load_dataset, split_dataset
from spam_classification.samples import generate_batch


st.set_page_config(page_title="Spam Classification Demo", layout="wide")
st.title("ğŸ“§ Spam Classification â€” Baseline Demo")
st.caption("TF-IDF + LinearSVC baseline with optional calibration; metrics and inference UI.")


ARTIFACTS_DIR = "artifacts"
DATA_DEFAULT = "sms_spam_no_header.csv"


@st.cache_resource
def _load_pipeline_cached(artifacts_dir: str = ARTIFACTS_DIR):
    try:
        return load_pipeline(artifacts_dir)
    except Exception as e:
        st.warning(f"Pipeline æœªè¼‰å…¥ï¼š{e}")
        return None


def _load_metrics(artifacts_dir: str = ARTIFACTS_DIR) -> dict | None:
    p = Path(artifacts_dir) / "metrics.json"
    if not p.exists():
        return None
    try:
        return json.loads(p.read_text())
    except Exception:
        return None


def _plot_confusion(cm: np.ndarray, labels: Tuple[str, str]):
    df_cm = pd.DataFrame(cm, index=labels, columns=labels)
    df_cm = df_cm.reset_index().melt(id_vars="index")
    df_cm.columns = ["True", "Pred", "Count"]
    chart = (
        alt.Chart(df_cm)
        .mark_rect()
        .encode(
            x=alt.X("Pred:N", title="Predicted"),
            y=alt.Y("True:N", title="True"),
            color=alt.Color("Count:Q", scale=alt.Scale(scheme="blues")),
            tooltip=["True", "Pred", "Count"],
        )
    )
    st.altair_chart(chart, use_container_width=True)


def _top_features(pipeline, top_n: int = 20) -> pd.DataFrame | None:
    try:
        tfidf = pipeline.named_steps["tfidf"]
        feature_names = np.array(tfidf.get_feature_names_out())
        clf = pipeline.named_steps["clf"]
        # unwrap calibrated classifier if used
        if hasattr(clf, "estimator"):
            base = clf.estimator
        else:
            base = clf
        # For binary classification, coef_ shape is (1, n_features) or (2, n_features)
        coefs = getattr(base, "coef_", None)
        if coefs is None:
            return None
        # assume positive class is spam; take largest positive weights
        weights = coefs[0] if coefs.ndim == 2 else coefs
        idx = np.argsort(weights)[::-1][:top_n]
        return pd.DataFrame({"feature": feature_names[idx], "weight": weights[idx]})
    except Exception:
        return None


def _top_tokens_by_class(pipeline, top_n: int = 20) -> tuple[pd.DataFrame | None, pd.DataFrame | None]:
    """Return Top-N tokens for ham (negative weights) and spam (positive weights)."""
    try:
        tfidf = pipeline.named_steps["tfidf"]
        feature_names = np.array(tfidf.get_feature_names_out())
        clf = pipeline.named_steps["clf"]
        if hasattr(clf, "estimator"):
            base = clf.estimator
        else:
            base = clf
        coefs = getattr(base, "coef_", None)
        if coefs is None:
            return None, None
        weights = coefs[0] if coefs.ndim == 2 else coefs
        # spam: largest positive weights
        spam_idx = np.argsort(weights)[::-1][:top_n]
        # ham: most negative weights
        ham_idx = np.argsort(weights)[:top_n]
        df_spam = pd.DataFrame({"token": feature_names[spam_idx], "weight": weights[spam_idx]})
        df_ham = pd.DataFrame({"token": feature_names[ham_idx], "weight": weights[ham_idx]})
        return df_ham, df_spam
    except Exception:
        return None, None


# å–®é ä»‹é¢ï¼šç§»é™¤å´æ¬„é¸å–®ï¼Œæ”¹ç‚ºåœ¨åŒä¸€é é€£çºŒå‘ˆç¾å„å€å¡Š
data_path = st.text_input("è³‡æ–™æª”æ¡ˆè·¯å¾‘", value=DATA_DEFAULT)
st.divider()


st.subheader("æ¨¡å‹è¨“ç·´")
test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)
seed = st.number_input("éš¨æ©Ÿç¨®å­", value=42, step=1)
calibrated = st.checkbox("å•Ÿç”¨æ¦‚ç‡æ ¡æº– (CalibratedClassifierCV)", value=True)
max_features = st.number_input("TF-IDF æœ€å¤§ç‰¹å¾µæ•¸", value=20000, step=1000)
run = st.button("é–‹å§‹è¨“ç·´")

if run:
    if not Path(data_path).exists():
        st.error(f"è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼š{data_path}")
    else:
        with st.spinner("è¨“ç·´ä¸­ï¼Œè«‹ç¨å€™..."):
            metrics = train_fn(
                csv_path=data_path,
                out_dir=ARTIFACTS_DIR,
                test_size=float(test_size),
                random_state=int(seed),
                calibrated=bool(calibrated),
                max_features=int(max_features),
            )
        st.success("è¨“ç·´å®Œæˆï¼")
        st.json(metrics)


st.divider()
st.subheader("å–®è¨Šæ¯æ¨è«–")
message = st.text_area("è¼¸å…¥æ¬²åˆ†é¡çš„è¨Šæ¯æ–‡æœ¬")
predict = st.button("æ¨è«–")

if predict:
    pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
    if pipeline is None:
        st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
    else:
        label, conf = infer_single(message, ARTIFACTS_DIR)
        st.write({"label": label, "confidence": round(conf, 4)})


st.divider()
st.subheader("è¨Šæ¯æ¨è«–æ¸¬è©¦å™¨ï¼ˆè‡ªå‹•ç”¢ç”Ÿå¸¸è¦‹æ–‡æœ¬ï¼‰")
cols_gen = st.columns(4)
with cols_gen[0]:
    lang_opt = st.radio("èªè¨€", options=["ä¸­æ–‡", "English"], index=0, horizontal=True)
    lang = "zh" if lang_opt == "ä¸­æ–‡" else "en"
with cols_gen[1]:
    category_opt = st.selectbox("é¡åˆ¥", options=["éš¨æ©Ÿ", "spam", "ham", "æ··åˆ"], index=0)
    category_map = {"éš¨æ©Ÿ": "random", "spam": "spam", "ham": "ham", "æ··åˆ": "mixed"}
    category = category_map[category_opt]
with cols_gen[2]:
    n_samples = st.slider("ç”Ÿæˆæ•¸é‡", min_value=1, max_value=10, value=3)
with cols_gen[3]:
    spam_ratio = st.slider("æ··åˆä¸­çš„ spam æ¯”ä¾‹", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

do_generate = st.button("ç”¢ç”Ÿä¸¦æ¨è«–")
if do_generate:
    pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
    if pipeline is None:
        st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
    else:
        batch = generate_batch(n=n_samples, lang=lang, category=category, spam_ratio=spam_ratio)
        for i, s in enumerate(batch, start=1):
            lbl, conf = infer_single(s["text"], ARTIFACTS_DIR)
            ok = (lbl == s["expected_label"]) if s.get("expected_label") else None
            with st.container(border=True):
                st.markdown(f"**è¨Šæ¯ {i}**ï¼ˆ{s['lang']} / æœŸæœ›ï¼š{s['expected_label']}ï¼‰")
                st.write(s["text"])
                st.write({"predicted": lbl, "confidence": round(conf, 4)})
                if ok is True:
                    st.success("é æ¸¬èˆ‡æœŸæœ›ä¸€è‡´ã€‚")
                elif ok is False:
                    st.warning("é æ¸¬èˆ‡æœŸæœ›ä¸ä¸€è‡´ï¼Œè«‹æª¢è¦–æ¨£æœ¬æˆ–èª¿æ•´æ¨¡å‹ã€‚")


st.divider()
st.subheader("è©•ä¼°æŒ‡æ¨™èˆ‡è¦–è¦ºåŒ–")
metrics = _load_metrics(ARTIFACTS_DIR)
if not metrics:
    st.warning("å°šæœªæ‰¾åˆ° metrics.jsonï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡ŠåŸ·è¡Œä¸€æ¬¡è¨“ç·´ä»¥ç”¢ç”Ÿè©•ä¼°æŒ‡æ¨™ã€‚")
else:
    st.metric("Accuracy", f"{metrics['accuracy']:.4f}")
    st.metric("F1 (weighted)", f"{metrics['f1_weighted']:.4f}")

    # ä¾æ“šè¨˜éŒ„çš„ test_size/seed é‡å»ºæ¸¬è©¦é›†ä»¥ç”¢ç”Ÿè¦–è¦ºåŒ–ï¼ˆä½¿ç”¨å·²è¨“ç·´ pipeline é æ¸¬ï¼‰
    csv_path = data_path if data_path else DATA_DEFAULT
    df = load_dataset(csv_path)
    X_train, X_test, y_train, y_test = split_dataset(
        df, test_size=float(metrics.get("test_size", 0.2)), random_state=int(metrics.get("random_state", 42))
    )
    pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
    if pipeline is None:
        st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
    else:
        preds = pipeline.predict(X_test)
        labels = ("ham", "spam")
        cm = confusion_matrix(y_test, preds, labels=list(labels))
        st.write("Confusion Matrix")
        _plot_confusion(cm, labels)

        st.write("Classification Report (per class)")
        report = classification_report(y_test, preds, labels=list(labels), output_dict=True, zero_division=0)
        df_rep = pd.DataFrame(
            {
                "label": labels,
                "precision": [report[l]["precision"] for l in labels],
                "recall": [report[l]["recall"] for l in labels],
                "f1": [report[l]["f1-score"] for l in labels],
                "support": [report[l]["support"] for l in labels],
            }
        )
        st.dataframe(df_rep, use_container_width=True)

        # ROC / PR curves
        st.write("ROC èˆ‡ Precision-Recall æ›²ç·š")
        # positive class is spam -> y_true_binary: 1 for spam, 0 for ham
        y_true_bin = np.array([1 if y == "spam" else 0 for y in y_test])
        try:
            # Use probability if available
            proba = pipeline.predict_proba(X_test)
            # Find index for positive class
            classes = list(pipeline.named_steps["clf"].classes_)
            pos_idx = classes.index("spam")
            y_scores = proba[:, pos_idx]
        except Exception:
            # Fall back to decision_function
            try:
                y_scores = pipeline.decision_function(X_test)
                # normalize to [0,1]
                y_scores = 1 / (1 + np.exp(-y_scores))
                st.info("æ¨¡å‹æœªæ ¡æº–ï¼ŒROC/PR ä»¥ decision_function è¿‘ä¼¼ç”Ÿæˆã€‚")
            except Exception:
                y_scores = None
        if y_scores is not None:
            fpr, tpr, _ = roc_curve(y_true_bin, y_scores)
            prec, rec, _ = precision_recall_curve(y_true_bin, y_scores)
            df_roc = pd.DataFrame({"FPR": fpr, "TPR": tpr})
            df_pr = pd.DataFrame({"Recall": rec, "Precision": prec})
            roc_chart = alt.Chart(df_roc).mark_line().encode(x="FPR", y="TPR")
            pr_chart = alt.Chart(df_pr).mark_line().encode(x="Recall", y="Precision")
            cols = st.columns(2)
            with cols[0]:
                st.altair_chart(roc_chart, use_container_width=True)
            with cols[1]:
                st.altair_chart(pr_chart, use_container_width=True)

        st.write("Top Tokens by Classï¼ˆham/spamï¼‰")
        df_ham, df_spam = _top_tokens_by_class(pipeline, top_n=20)
        if df_ham is not None and df_spam is not None:
            cols2 = st.columns(2)
            with cols2[0]:
                st.dataframe(df_ham, use_container_width=True)
            with cols2[1]:
                st.dataframe(df_spam, use_container_width=True)
        else:
            st.info("ç„¡æ³•æ“·å– ham/spam é—œéµå­—æ’åï¼ˆå¯èƒ½ä¸æ”¯æ´æˆ–å°šæœªè¨“ç·´ï¼‰ã€‚")


st.divider()
st.subheader("Artifacts æª¢è¦–/ä¸‹è¼‰")
p = Path(ARTIFACTS_DIR)
if not p.exists():
    st.warning("å°šæœªç”Ÿæˆ artifactsã€‚")
else:
    files = list(p.glob("*"))
    st.write("ç¾æœ‰æª”æ¡ˆï¼š", [f.name for f in files])
    # æä¾›ä¸‹è¼‰æŒ‰éˆ•ï¼ˆmetrics.json / model.joblibï¼‰
    m = p / "metrics.json"
    if m.exists():
        st.download_button("ä¸‹è¼‰ metrics.json", data=m.read_text(), file_name="metrics.json")
    model = p / "model.joblib"
    if model.exists():
        st.download_button("ä¸‹è¼‰ model.joblib", data=model.read_bytes(), file_name="model.joblib")
