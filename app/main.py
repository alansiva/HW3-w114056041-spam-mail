from __future__ import annotations

import json
from pathlib import Path
from typing import Tuple

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve

from spam_classification.train import train as train_fn
from spam_classification.infer import infer_single, load_pipeline
from spam_classification.data import load_dataset, split_dataset
from spam_classification.samples import generate_batch
from spam_classification.visualize import top_tokens_by_class_from_data, save_top_tokens_csv


st.set_page_config(page_title="Spam Classification Demo", layout="wide")
st.title("ğŸ“§ Spam Classification â€” Baseline Demo")
st.caption("TF-IDF + LinearSVC baseline with optional calibration; metrics and inference UI.")

# Anchors èˆ‡å´é‚Šå°è¦½
st.markdown("<a id='top'></a>", unsafe_allow_html=True)
st.sidebar.header("é¸æ“‡åŠŸèƒ½")
nav = st.sidebar.radio(
    "é¸æ“‡åŠŸèƒ½",
    options=["è¨“ç·´", "æ¨è«–", "æŒ‡æ¨™/è¦–è¦ºåŒ–", "é—œéµå­—æ’è¡Œ", "Artifacts"],
    index=0,
)
st.markdown(
    "ç›®éŒ„ï¼š [è¨“ç·´](#train) | [æ¨è«–](#infer) | [æŒ‡æ¨™/è¦–è¦ºåŒ–](#metrics) | [é—œéµå­—æ’è¡Œ](#keywords) | [Artifacts](#artifacts)",
    unsafe_allow_html=True,
)


ARTIFACTS_DIR = "artifacts"
DATA_DEFAULT = "sms_spam_no_header.csv"


@st.cache_resource
def _load_pipeline_cached(artifacts_dir: str = ARTIFACTS_DIR):
    try:
        return load_pipeline(artifacts_dir)
    except Exception as e:
        st.warning(f"Pipeline æœªè¼‰å…¥ï¼š{e}")
        return None


def _load_metrics(artifacts_dir: str = ARTIFACTS_DIR) -> dict | None:
    p = Path(artifacts_dir) / "metrics.json"
    if not p.exists():
        return None
    try:
        return json.loads(p.read_text())
    except Exception:
        return None


def _plot_confusion(cm: np.ndarray, labels: Tuple[str, str]):
    df_cm = pd.DataFrame(cm, index=labels, columns=labels)
    df_cm = df_cm.reset_index().melt(id_vars="index")
    df_cm.columns = ["True", "Pred", "Count"]
    chart = (
        alt.Chart(df_cm)
        .mark_rect()
        .encode(
            x=alt.X("Pred:N", title="Predicted"),
            y=alt.Y("True:N", title="True"),
            color=alt.Color("Count:Q", scale=alt.Scale(scheme="blues")),
            tooltip=["True", "Pred", "Count"],
        )
    )
    st.altair_chart(chart, use_container_width=True)


def _top_features(pipeline, top_n: int = 20) -> pd.DataFrame | None:
    try:
        tfidf = pipeline.named_steps["tfidf"]
        feature_names = np.array(tfidf.get_feature_names_out())
        clf = pipeline.named_steps["clf"]
        # unwrap calibrated classifier if used
        if hasattr(clf, "estimator"):
            base = clf.estimator
        else:
            base = clf
        # For binary classification, coef_ shape is (1, n_features) or (2, n_features)
        coefs = getattr(base, "coef_", None)
        if coefs is None:
            return None
        # assume positive class is spam; take largest positive weights
        weights = coefs[0] if coefs.ndim == 2 else coefs
        idx = np.argsort(weights)[::-1][:top_n]
        return pd.DataFrame({"feature": feature_names[idx], "weight": weights[idx]})
    except Exception:
        return None


def _top_tokens_by_class(pipeline, top_n: int = 20) -> tuple[pd.DataFrame | None, pd.DataFrame | None]:
    """Return Top-N tokens for ham (negative weights) and spam (positive weights)."""
    try:
        tfidf = pipeline.named_steps["tfidf"]
        feature_names = np.array(tfidf.get_feature_names_out())
        clf = pipeline.named_steps["clf"]
        if hasattr(clf, "estimator"):
            base = clf.estimator
        else:
            base = clf
        coefs = getattr(base, "coef_", None)
        if coefs is None:
            return None, None
        weights = coefs[0] if coefs.ndim == 2 else coefs
        # spam: largest positive weights
        spam_idx = np.argsort(weights)[::-1][:top_n]
        # ham: most negative weights
        ham_idx = np.argsort(weights)[:top_n]
        df_spam = pd.DataFrame({"token": feature_names[spam_idx], "weight": weights[spam_idx]})
        df_ham = pd.DataFrame({"token": feature_names[ham_idx], "weight": weights[ham_idx]})
        return df_ham, df_spam
    except Exception:
        return None, None


# å–®é ä»‹é¢ï¼šç§»é™¤å´æ¬„é¸å–®ï¼Œæ”¹ç‚ºåœ¨åŒä¸€é é€£çºŒå‘ˆç¾å„å€å¡Š
data_path = st.text_input("è³‡æ–™æª”æ¡ˆè·¯å¾‘", value=DATA_DEFAULT)
st.divider()


st.markdown("<a id='train'></a>", unsafe_allow_html=True)
with st.expander("è¨“ç·´", expanded=(nav == "è¨“ç·´")):
    st.subheader("æ¨¡å‹è¨“ç·´")
    test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)
    seed = st.number_input("éš¨æ©Ÿç¨®å­", value=42, step=1)
    calibrated = st.checkbox("å•Ÿç”¨æ¦‚ç‡æ ¡æº– (CalibratedClassifierCV)", value=True)
    max_features = st.number_input("TF-IDF æœ€å¤§ç‰¹å¾µæ•¸", value=20000, step=1000)
    run = st.button("é–‹å§‹è¨“ç·´")

    if run:
        if not Path(data_path).exists():
            st.error(f"è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼š{data_path}")
        else:
            with st.spinner("è¨“ç·´ä¸­ï¼Œè«‹ç¨å€™..."):
                metrics = train_fn(
                    csv_path=data_path,
                    out_dir=ARTIFACTS_DIR,
                    test_size=float(test_size),
                    random_state=int(seed),
                    calibrated=bool(calibrated),
                    max_features=int(max_features),
                )
            st.success("è¨“ç·´å®Œæˆï¼")
            st.json(metrics)
    st.markdown("[å›åˆ°é ‚ç«¯](#top)", unsafe_allow_html=True)


st.markdown("<a id='infer'></a>", unsafe_allow_html=True)
with st.expander("æ¨è«–ï¼ˆå–®å‰‡èˆ‡è‡ªå‹•æ¸¬è©¦å™¨ï¼‰", expanded=(nav == "æ¨è«–")):
    st.subheader("å–®è¨Šæ¯æ¨è«–")
    message = st.text_area("è¼¸å…¥æ¬²åˆ†é¡çš„è¨Šæ¯æ–‡æœ¬")
    predict = st.button("æ¨è«–")

    if predict:
        pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
        if pipeline is None:
            st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
        else:
            label, conf = infer_single(message, ARTIFACTS_DIR)
            st.write({"label": label, "confidence": round(conf, 4)})

    st.divider()
    st.subheader("è¨Šæ¯æ¨è«–æ¸¬è©¦å™¨ï¼ˆè‡ªå‹•ç”¢ç”Ÿå¸¸è¦‹æ–‡æœ¬ï¼‰")
    cols_gen = st.columns(4)
    with cols_gen[0]:
        lang_opt = st.radio("èªè¨€", options=["ä¸­æ–‡", "English"], index=0, horizontal=True)
        lang = "zh" if lang_opt == "ä¸­æ–‡" else "en"
    with cols_gen[1]:
        category_opt = st.selectbox("é¡åˆ¥", options=["éš¨æ©Ÿ", "spam", "ham", "æ··åˆ"], index=0)
        category_map = {"éš¨æ©Ÿ": "random", "spam": "spam", "ham": "ham", "æ··åˆ": "mixed"}
        category = category_map[category_opt]
    with cols_gen[2]:
        n_samples = st.slider("ç”Ÿæˆæ•¸é‡", min_value=1, max_value=10, value=3)
    with cols_gen[3]:
        spam_ratio = st.slider("æ··åˆä¸­çš„ spam æ¯”ä¾‹", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

    do_generate = st.button("ç”¢ç”Ÿä¸¦æ¨è«–")
    if do_generate:
        pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
        if pipeline is None:
            st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
        else:
            batch = generate_batch(n=n_samples, lang=lang, category=category, spam_ratio=spam_ratio)
            for i, s in enumerate(batch, start=1):
                lbl, conf = infer_single(s["text"], ARTIFACTS_DIR)
                ok = (lbl == s["expected_label"]) if s.get("expected_label") else None
                with st.container(border=True):
                    st.markdown(f"**è¨Šæ¯ {i}**ï¼ˆ{s['lang']} / æœŸæœ›ï¼š{s['expected_label']}ï¼‰")
                    st.write(s["text"])
                    st.write({"predicted": lbl, "confidence": round(conf, 4)})
                    if ok is True:
                        st.success("é æ¸¬èˆ‡æœŸæœ›ä¸€è‡´ã€‚")
                    elif ok is False:
                        st.warning("é æ¸¬èˆ‡æœŸæœ›ä¸ä¸€è‡´ï¼Œè«‹æª¢è¦–æ¨£æœ¬æˆ–èª¿æ•´æ¨¡å‹ã€‚")
    st.markdown("[å›åˆ°é ‚ç«¯](#top)", unsafe_allow_html=True)


st.markdown("<a id='metrics'></a>", unsafe_allow_html=True)
with st.expander("æŒ‡æ¨™/è¦–è¦ºåŒ–", expanded=(nav == "æŒ‡æ¨™/è¦–è¦ºåŒ–")):
    st.subheader("è©•ä¼°æŒ‡æ¨™èˆ‡è¦–è¦ºåŒ–")
    metrics = _load_metrics(ARTIFACTS_DIR)
    if not metrics:
        st.warning("å°šæœªæ‰¾åˆ° metrics.jsonï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡ŠåŸ·è¡Œä¸€æ¬¡è¨“ç·´ä»¥ç”¢ç”Ÿè©•ä¼°æŒ‡æ¨™ã€‚")
    else:
        st.metric("Accuracy", f"{metrics['accuracy']:.4f}")
        st.metric("F1 (weighted)", f"{metrics['f1_weighted']:.4f}")

        # ä¾æ“šè¨˜éŒ„çš„ test_size/seed é‡å»ºæ¸¬è©¦é›†ä»¥ç”¢ç”Ÿè¦–è¦ºåŒ–ï¼ˆä½¿ç”¨å·²è¨“ç·´ pipeline é æ¸¬ï¼‰
        csv_path = data_path if data_path else DATA_DEFAULT
        df = load_dataset(csv_path)
        X_train, X_test, y_train, y_test = split_dataset(
            df, test_size=float(metrics.get("test_size", 0.2)), random_state=int(metrics.get("random_state", 42))
        )
        pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
        if pipeline is None:
            st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
        else:
            # å¯èª¿æ±ºç­–é–¾å€¼ï¼ˆspam ç‚ºæ­£é¡ï¼‰ï¼Œå„ªå…ˆä½¿ç”¨ predict_probaï¼Œå¦å‰‡ä»¥ decision_function ç¶“ sigmoid è¿‘ä¼¼
            cols_thr = st.columns(2)
            with cols_thr[0]:
                threshold = st.slider("æ±ºç­–é–¾å€¼ï¼ˆspamï¼‰", min_value=0.0, max_value=1.0, value=0.5, step=0.05)
            with cols_thr[1]:
                st.caption("èªªæ˜ï¼šè‹¥æ¨¡å‹æœªæ ¡æº–ï¼Œå°‡ä»¥ decision_function ç¶“ sigmoid è¿‘ä¼¼åˆ†æ•¸å†å¥—ç”¨é–¾å€¼ã€‚")

            try:
                proba = pipeline.predict_proba(X_test)
                classes = list(pipeline.named_steps["clf"].classes_)
                pos_idx = classes.index("spam")
                scores = proba[:, pos_idx]
            except Exception:
                try:
                    margins = pipeline.decision_function(X_test)
                    scores = 1 / (1 + np.exp(-margins))
                    st.info("æ¨¡å‹æœªæ ¡æº–ï¼Œé–¾å€¼å¥—ç”¨æ–¼ decision_function è¿‘ä¼¼åˆ†æ•¸ã€‚")
                except Exception:
                    scores = None

            if scores is not None:
                preds = np.where(scores >= threshold, "spam", "ham")
            else:
                preds = pipeline.predict(X_test)
            labels = ("ham", "spam")
            cm = confusion_matrix(y_test, preds, labels=list(labels))
            st.write("Confusion Matrix")
            _plot_confusion(cm, labels)

            st.write("Classification Report (per class)")
            report = classification_report(y_test, preds, labels=list(labels), output_dict=True, zero_division=0)
            df_rep = pd.DataFrame(
                {
                    "label": labels,
                    "precision": [report[lab]["precision"] for lab in labels],
                    "recall": [report[lab]["recall"] for lab in labels],
                    "f1": [report[lab]["f1-score"] for lab in labels],
                    "support": [report[lab]["support"] for lab in labels],
                }
            )
            st.dataframe(df_rep, use_container_width=True)

            # ROC / PR curves
            st.write("ROC èˆ‡ Precision-Recall æ›²ç·š")
            # positive class is spam -> y_true_binary: 1 for spam, 0 for ham
            y_true_bin = np.array([1 if y == "spam" else 0 for y in y_test])
            try:
                # Use probability if available
                proba = pipeline.predict_proba(X_test)
                # Find index for positive class
                classes = list(pipeline.named_steps["clf"].classes_)
                pos_idx = classes.index("spam")
                y_scores = proba[:, pos_idx]
            except Exception:
                # Fall back to decision_function
                try:
                    y_scores = pipeline.decision_function(X_test)
                    # normalize to [0,1]
                    y_scores = 1 / (1 + np.exp(-y_scores))
                    st.info("æ¨¡å‹æœªæ ¡æº–ï¼ŒROC/PR ä»¥ decision_function è¿‘ä¼¼ç”Ÿæˆã€‚")
                except Exception:
                    y_scores = None
            if y_scores is not None:
                fpr, tpr, _ = roc_curve(y_true_bin, y_scores)
                prec, rec, _ = precision_recall_curve(y_true_bin, y_scores)
                df_roc = pd.DataFrame({"FPR": fpr, "TPR": tpr})
                df_pr = pd.DataFrame({"Recall": rec, "Precision": prec})
                roc_chart = alt.Chart(df_roc).mark_line().encode(x="FPR", y="TPR")
                pr_chart = alt.Chart(df_pr).mark_line().encode(x="Recall", y="Precision")
                cols = st.columns(2)
                with cols[0]:
                    st.altair_chart(roc_chart, use_container_width=True)
                with cols[1]:
                    st.altair_chart(pr_chart, use_container_width=True)

            st.write("Top Tokens by Classï¼ˆham/spamï¼‰")
            top_n = st.slider("Top-N tokens", min_value=5, max_value=50, value=20, step=5)
            df_ham, df_spam = _top_tokens_by_class(pipeline, top_n=int(top_n))
            if df_ham is not None and df_spam is not None:
                cols2 = st.columns(2)
                with cols2[0]:
                    st.dataframe(df_ham, use_container_width=True)
                with cols2[1]:
                    st.dataframe(df_spam, use_container_width=True)
            else:
                st.info("ç„¡æ³•æ“·å– ham/spam é—œéµå­—æ’åï¼ˆå¯èƒ½ä¸æ”¯æ´æˆ–å°šæœªè¨“ç·´ï¼‰ã€‚")
    st.markdown("[å›åˆ°é ‚ç«¯](#top)", unsafe_allow_html=True)

st.markdown("<a id='keywords'></a>", unsafe_allow_html=True)
with st.expander("é—œéµå­—æ’è¡Œï¼ˆham/spamï¼‰", expanded=(nav == "é—œéµå­—æ’è¡Œ")):
    st.subheader("é—œéµå­—æ’è¡Œï¼ˆham/spamï¼‰")
    top_n_kw = st.slider("Top-N tokens", min_value=5, max_value=50, value=20, step=5, key="kw_top_n")
    source = st.radio("ä¾†æº", options=["æ¨¡å‹ä¿‚æ•¸", "è¨“ç·´è³‡æ–™å¹³å‡TF-IDF"], index=0, horizontal=True, key="kw_source")

    pipeline = _load_pipeline_cached(ARTIFACTS_DIR)
    if pipeline is None:
        st.error("å°šæœªæ‰¾åˆ°å·²è¨“ç·´çš„æ¨¡å‹ï¼Œè«‹å…ˆåœ¨ä¸Šæ–¹ã€æ¨¡å‹è¨“ç·´ã€å€å¡Šé€²è¡Œè¨“ç·´ã€‚")
    else:
        df_ham_kw = None
        df_spam_kw = None
        if source == "æ¨¡å‹ä¿‚æ•¸":
            df_ham_kw, df_spam_kw = _top_tokens_by_class(pipeline, top_n=int(top_n_kw))
        else:
            metrics_cached = _load_metrics(ARTIFACTS_DIR)
            csv_path_kw = data_path if data_path else DATA_DEFAULT
            df_kw = load_dataset(csv_path_kw)
            ts = float(metrics_cached.get("test_size", 0.2)) if metrics_cached else 0.2
            rs = int(metrics_cached.get("random_state", 42)) if metrics_cached else 42
            X_train_kw, X_test_kw, y_train_kw, y_test_kw = split_dataset(df_kw, test_size=ts, random_state=rs)
            df_ham_kw, df_spam_kw = top_tokens_by_class_from_data(pipeline, X_train_kw, y_train_kw, top_n=int(top_n_kw))

        if df_ham_kw is not None and df_spam_kw is not None:
            cols_kw = st.columns(2)
            with cols_kw[0]:
                st.write("Ham Top Tokens")
                st.dataframe(df_ham_kw, use_container_width=True)
                st.download_button("ä¸‹è¼‰ ham CSV", data=df_ham_kw.to_csv(index=False), file_name="top_tokens_ham.csv")
            with cols_kw[1]:
                st.write("Spam Top Tokens")
                st.dataframe(df_spam_kw, use_container_width=True)
                st.download_button("ä¸‹è¼‰ spam CSV", data=df_spam_kw.to_csv(index=False), file_name="top_tokens_spam.csv")

            # åŒ¯å‡ºåˆ° artifactsï¼ˆè‹¥ä¾†æºç‚ºæ¨¡å‹ä¿‚æ•¸ï¼Œç›´æ¥ä½¿ç”¨ save_top_tokens_csvï¼›å¦å‰‡ä»¥ç›®å‰çµæœå¯«å‡ºï¼‰
            do_export = st.button("åŒ¯å‡ºè‡³ artifacts")
            if do_export:
                try:
                    if source == "æ¨¡å‹ä¿‚æ•¸":
                        save_top_tokens_csv(pipeline, out_dir=ARTIFACTS_DIR, top_n=int(top_n_kw))
                    else:
                        Path(ARTIFACTS_DIR).mkdir(parents=True, exist_ok=True)
                        (Path(ARTIFACTS_DIR) / "top_tokens_ham.csv").write_text(df_ham_kw.to_csv(index=False))
                        (Path(ARTIFACTS_DIR) / "top_tokens_spam.csv").write_text(df_spam_kw.to_csv(index=False))
                    st.success("å·²åŒ¯å‡ºé—œéµå­—æ’è¡Œè‡³ artifactsã€‚")
                except Exception as e:
                    st.error(f"åŒ¯å‡ºå¤±æ•—ï¼š{e}")
        else:
            if source == "æ¨¡å‹ä¿‚æ•¸":
                st.info("ç„¡æ³•é€éæ¨¡å‹ä¿‚æ•¸æ“·å–é—œéµå­—æ’è¡Œï¼Œè«‹æ”¹ç”¨ã€è¨“ç·´è³‡æ–™å¹³å‡TF-IDFã€ä¾†æºã€‚")
            else:
                st.info("ç„¡æ³•é€éè³‡æ–™å‚™æ´æ–¹å¼ç”¢ç”Ÿé—œéµå­—æ’è¡Œï¼Œè«‹ç¢ºèªè³‡æ–™èˆ‡æ¨¡å‹æ˜¯å¦å®Œæ•´ã€‚")
    st.markdown("[å›åˆ°é ‚ç«¯](#top)", unsafe_allow_html=True)


st.markdown("<a id='artifacts'></a>", unsafe_allow_html=True)
with st.expander("Artifacts", expanded=(nav == "Artifacts")):
    st.subheader("Artifacts æª¢è¦–/ä¸‹è¼‰")
    p = Path(ARTIFACTS_DIR)
    if not p.exists():
        st.warning("å°šæœªç”Ÿæˆ artifactsã€‚")
    else:
        files = list(p.glob("*"))
        st.write("ç¾æœ‰æª”æ¡ˆï¼š", [f.name for f in files])
        # æä¾›ä¸‹è¼‰æŒ‰éˆ•ï¼ˆmetrics.json / model.joblibï¼‰
        m = p / "metrics.json"
        if m.exists():
            st.download_button("ä¸‹è¼‰ metrics.json", data=m.read_text(), file_name="metrics.json")
        model = p / "model.joblib"
        if model.exists():
            st.download_button("ä¸‹è¼‰ model.joblib", data=model.read_bytes(), file_name="model.joblib")
    st.markdown("[å›åˆ°é ‚ç«¯](#top)", unsafe_allow_html=True)
