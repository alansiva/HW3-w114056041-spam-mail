# OpenSpec 變更提案：新增「自動產生訊息推論測試器」

## 背景與動機
- 目前 UI 已提供手動單訊息推論，但缺少能快速建立多筆「常見訊息」並立即驗證模型的互動測試器。
- 加入可自動產生常見 spam/ham 訊息（支援中/英），能協助：
  - 做功能驗證與教材示範（課堂作業展示）。
  - 觀察不同訊息模式下的分類行為與信心分數。
  - 方便比對「期望標籤」與「模型預測」是否一致。

## 提案內容
1. 新增模組 `spam_classification/samples.py`：
   - 內建中/英 spam 與 ham 的典型樣板與片語，提供 `generate_message()` 與 `generate_batch()` API。
   - 支援占位符（url/phone/code/time）自動填入，避免使用真實個資或網址。
2. 擴充 Streamlit 單頁 UI：
   - 新增區塊「訊息推論測試器（自動產生常見文本）」：
     - 控制項：語言（中文/English）、類別（spam/ham/混合/隨機）、生成數量、混合 spam 比例。
     - 一鍵生成並呼叫既有推論管線，顯示每則訊息的「期望標籤 / 預測標籤 / 信心分數」。
     - 對不一致的案例提供醒目提示，便於教學與除錯。
3. CLI（後續）
   - 提供批次生成與推論的命令列工具，輸出 JSON artifacts，便於離線評估或 CI 介接。

## 影響與相容性
- 不影響既有訓練流程與模型 artifacts；新增模組與 UI 區塊相對獨立。
- 後續若加入 CLI，將新增可選 artifacts 檔（如 `auto_tester_predictions.json`）。

## 實作重點
- 樣本訊息模板以教學為目的，不涉及真實網址／電話；所有占位符使用安全假資料。
- 模型若未校準（無 `predict_proba`），以 `decision_function` 經 sigmoid 近似分數顯示信心。

## 驗收標準
- UI 可生成指定數量的 spam/ham 訊息（中/英），並顯示每則的預測標籤與信心分數。
- 混合模式可設定 spam 比例，生成的各類別比例大致符合設定。
- 對「期望標籤」與「預測標籤」不一致者，有視覺提示（如警示訊息）。

## 非目標
- 不引入大型語言模型或複雜文本生成；僅以模板與片語組合為主。
- 不做資料擴增或模型再訓練的自動觸發（可在後續提案討論）。

## 時程建議
- Day 1：撰寫提案與任務拆解、建立樣本模組、擴充 UI 區塊。
- Day 2：補 CLI 與 artifacts 輸出、撰寫測試與文件、驗收與微調。

